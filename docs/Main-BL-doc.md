# llm-copypaster — copypaster-bl.md

Документ описывает baseline (BL) спецификацию VS Code extension **llm-copypaster**: архитектуру, модули, конфигурацию, форматы входа/выхода и план развития.

---

## 0.a) Версия документа

- Дата: 2026-02-20 16:03:59 (Europe/Zaporozhye)
- Изменения (vNext):
  - EditorToLlm: добавлен режим копирования **Path-Comment** (копировать выбранный скоуп файлов без LLM-обвязки: путь как `//`-комментарий + сырой контент)
  - EditorToLlm: добавлен выбор режима копирования (quick pick или фиксированный режим через настройки)
  - UX: добавлен флаг группировки пунктов контекстного меню в под-меню **LLM Copypaster**

---

## 0) Цели и позиционирование

**llm-copypaster** — расширение для цельного workflow “Editor ↔ LLM” с упором на:

- минимизацию рутины при подготовке контекста и применении результата
- максимальную конфигурируемость (регексы, форматы, промты, исключения, пер-LLM overrides)
- надежность (устойчивость к удалённым файлам, дублям табов, мусору из LLM, частичным фейлам)
- возможность поэтапного внедрения и совместимости с уже существующими расширениями

Функционально пересекается с:

- **collinc777.context-copy** (копирование контекста)
- **RonPark.paste-clipboard-to-files** (вставка “из буфера в файлы”)

Но задача llm-copypaster — **свести это в один управляемый pipeline**, который можно расширять (guided retry, patch-output, replace-blocks и т.д.).

---

## 1) Архитектура верхнего уровня

Расширение состоит из двух основных модулей:

1. **EditorToLlm Module**

- Собирает контекст из VS Code (файлы/вкладки/группы/solution explorer)
- Форматирует его как “LLM контекст”: конкатенация file listings
- Опционально добавляет промт-инструкцию про **формат ответа** (response format prompt)

2. **LlmToEditor Module**

- Берёт сырой LLM output из буфера обмена
- Валидирует, санитизирует и парсит в структурированный JSON
- Применяет изменения к workspace через VS Code API (создание/обновление/пометки на удаление)
- Дает управляемые ошибки + guided retry промты, чтобы чинить конкретные фейлы без ручной рутины

Дополнительно: “в будущем” возможен третий путь **replace-blocks** (patch-подход как золотая середина между git-diff и full-output), но текущий baseline ориентирован на **full-output**.

---

## 2) EditorToLlm Module

### 2.1. Назначение

Подготовка контекста для LLM:

- собрать набор файлов
- сконкатенировать листинги
- для каждого листинга добавить идентификатор (относительный путь + имя файла)
- обернуть листинг в code-fence
- опционально дописать в начало/конец дополнительный промт, который уточняет формат требуемого ответа

Идеологически близок к **collinc777.context-copy**, но с отличиями:

- возможность конкатенировать “response format prompt” (чтобы не зависеть от глобальной памяти/системной промты)
- возможность адаптировать input-форматирование, чтобы оптимизировать LLM-output (например, жёстко запретить патчи, попросить “full file only”, и т.п.)
- устойчивость к:
  - удалённым/недоступным файлам (не падать с ошибкой, а деградировать)
  - одному и тому же файлу, открытом в нескольких tab groups (дедупликация)
  - несинхронным состояниям UI (таб есть, файл уже удалён)

### 2.2. Источники файлов (File Selection)

Поддерживаемые сценарии:

- конкретный файл (active editor)
- все открытые файлы (all visible editors / open tabs)
- все файлы в конкретной tab group
- один/несколько файлов, выбранных в **Solution Explorer / Explorer / File Tree** (context menu)

### 2.3. Дедупликация и порядок

- **Дедупликация по workspace-relative path**
- Порядок формируется настраиваемо (по умолчанию рекомендуется):
  1. active file
  2. остальные открытые файлы (по порядку табов)
  3. выбранные в explorer файлы (если команда из explorer)
- При конфликте “один файл в разных группах” листинг должен появляться **один раз**

### 2.4. Обработка ошибок чтения файлов

Если файл недоступен:

- не падать всей командой
- добавить в результирующий контекст заметку (конфигурируемо), например:
  - пропустить файл тихо
  - вставить “placeholder listing” с описанием ошибки
  - собрать список warning’ов и показать notification

### 2.5. Формат вывода (LLM Context Output Format)

#### 2.5.1. Full listing формат (baseline)

Каждый файл выводится блоком:

- Заголовок: относительный путь
- Code fence: язык опционально определяется по extension (конфиг)
- Контент файла без изменений

Пример:

```ts
// # src/app/app.component.ts
// (file content here)
```

В baseline считается обязательным:

- **relative path** (например `src/app/app.component.ts`)
- **filename** (обычно уже часть relative path, но можно дополнительно дублировать в заголовке — конфиг)

#### 2.5.2. Response format prompt (опционально)

Модуль может добавлять промт, который прямо требует формат ответа LLM.

Задача: чтобы пользователь не “воевал” с memory/system prompt и мог включать/выключать инструкцию явно.

Примеры режимов (конфигурируемые):

- Full-output response (LLM возвращает полный файл целиком)
- Extension-response protocol (строгий concat file listings без лишнего текста)
- Patch-output (в будущем)

### 2.5.3. Path-Comment listing формат (новая опция)

Иногда нужно скопировать _тот же скоуп файлов_, но **не для модификации**, а _как контекст_, без необходимости отдельно объяснять LLM “это только read-only”.

Для этого EditorToLlm поддерживает альтернативный формат **Path-Comment**:

- каждый файл начинается со строки пути в виде `//`-комментария: `// relative/path.ext`
- далее идёт **сырой контент файла** (без code-fence, без backticks)
- response format prompt **не добавляется** (в этом режиме это не “LLM payload”)

Пример:

```txt
// src/app/app.component.ts
import { Component } from '@angular/core';
...
```

Назначение: удобно вставлять в чат/доку/внутренние заметки или как дополнительный фон, не провоцируя модель на попытку “ответить строго протоколом”.

### 2.5.4. Выбор режима копирования (контекст vs path-comment)

Выбор режима задаётся настройками:

- режим выбора:
  - `quickPick` — при выполнении команды копирования показывать выбор:
    - `LLM Context` (baseline формат с code-fence + опциональным response prompt)
    - `Path-Comment` (путь как `//` + сырой контент)
  - `fixed` — всегда использовать один режим, заданный в конфиге

- фиксированный режим (если выбран `fixed`):
  - `llmContext`
  - `pathComment`

---

## 3) LlmToEditor Module

### 3.1. Назначение

Принять LLM output из буфера обмена, сделать его применимым к workspace:

- определить, можно ли это распарсить
- убрать “LLM мусор” (лишние оговорки, fenced blocks, “Sure, here you go”, и т.п.)
- получить чистый структурированный набор изменений
- применить изменения корректно через VS Code API
- если не получилось — дать пользователю точное объяснение и guided retry инструменты

Pipeline:

1. Validation Submodule
2. Sanitization Submodule
3. Files Patcher Submodule

---

## 3.a) Validation Submodule

### 3.a.1. Назначение

Проверить “парсится ли вообще” текущий буфер и извлечь структурированное представление:

- на входе: raw clipboard text
- на выходе: JSON-структура “files payload”, пригодная для санитизации

### 3.a.2. Поддерживаемые форматы входа (минимум)

В baseline рекомендуется поддержать хотя бы:

- **concatenated file listings** (с заголовком пути + контентом)
- **fenced blocks** (`lang ... `)
- варианты заголовка:
  - `# relative/path.ext`
  - `// relative/path.ext`
  - `<!-- relative/path.ext -->`
  - `File: relative/path.ext` (опционально, как “грязный” формат)

Выходной JSON (концептуально):

```json
{
  "files": [
    {
      "path": "relative/path.ext",
      "content": "file content",
      "sourceRange": { "start": 123, "end": 456 }
    }
  ],
  "warnings": [],
  "errors": []
}
```

### 3.a.3. Ошибки валидации

Если вход нельзя корректно распарсить:

- показать notification с причиной
- предложить “Copy guided retry prompt” (см. Guided Retry)
- опционально: сохранить “сырой буфер” в лог/вывод (конфиг)

---

## 3.b) Sanitization Submodule

### 3.b.1. Назначение

Удалить мусор, который мешает парсингу/применению:

- убрать code fences `...`
- убрать префикс/суффикс текста “Here is the file…”
- убрать markdown-обвязки, если они попали в контент файла
- нормализовать переносы строк (конфиг)
- исправить частые LLM-артефакты (например, лишние тройные бэктики)

На входе: JSON после Validation
На выходе: “sanitized JSON” — тот же список файлов, но с очищенным `content`

### 3.b.2. Regex rules с исключениями по языкам

Ключевое требование: **каждый regex-rule должен поддерживать исключения**, например:

- “не применять rule для markdown”
- “не применять rule для python”
- “не применять для файлов с путями matching pattern”

Концепт настройки:

````json
{
  "sanitizationRules": [
    {
      "id": "strip-codefence",
      "pattern": "```[a-zA-Z0-9_-]*\\n|\\n```",
      "replaceWith": "",
      "disabledForLanguages": ["markdown"],
      "disabledForPaths": ["docs/"]
    }
  ]
}
````

### 3.b.3. Частичная санитизация

Если часть файлов санитизировать нельзя:

- не ломать всё целиком
- пометить файлы как failed, применить остальные (конфиг)
- сгенерировать guided retry промт только для сломанных

---

## 3.c) Files Patcher Submodule

### 3.c.1. Назначение

Применить sanitized JSON к workspace:

- обновить существующие файлы
- создать новые файлы
- для “удаления” — не удалять физически (baseline), а добавить комментарий “file is no longer needed” (конфиг)
- применять изменения через VS Code API, а не “мимо API”

Цель: решить проблемы RonPark.paste-clipboard-to-files:

- “сырость”, отсутствие конфигурации, детские болячки
- патчинг в обход VS Code API, из-за чего приходится костылить file-save и линтинг

### 3.c.2. Модель операций (Operations Model)

Рекомендуемый baseline: определять операции автоматически:

- если `path` существует — update
- если не существует — create
- delete в baseline как “comment marker” или “move to trash folder” (настраиваемо)

Концепт:

```json
{
  "files": [
    { "path": "src/a.ts", "content": "...", "operation": "update" },
    { "path": "src/new.ts", "content": "...", "operation": "create" },
    { "path": "src/old.ts", "content": "", "operation": "deleteMarker" }
  ]
}
```

### 3.c.3. Применение через VS Code API

- использовать WorkspaceEdit / TextDocumentEdit и т.п.
- после apply (опционально) запускать:
  - `vscode.commands.executeCommand('editor.action.formatDocument')`
    (по настройке, по типу файла, или глобально)

### 3.c.4. Конфликтные ситуации

- файл открыт и имеет unsaved changes
- файл readonly
- файл исчез в момент применения

Поведение должно быть конфигурируемым:

- пропустить
- спросить (quick pick)
- overwrite
- создать copy file (например `.llm-copy`)

---

## 4) Guided Retry (обязательная фича направления развития)

### 4.1. Идея

Ошибки не должны быть “тупыми нотификашками”.
Если что-то сломалось, extension должен:

- объяснить, что именно сломалось
- дать пользователю кнопку “Copy retry prompt”
- промт должен быть **точечным**, с указанием:
  - какой файл/операция сломалась
  - что именно не найдено / не распарсилось
  - какой формат ответа нужен
  - (опционально) приложить исходную версию файла как контекст

Пример guided retry сценария (концепт):

- “не найдена якорная строка XXX при попытке применить patch YYY”
- prompt: “LLM, пришли правильный anchor… вот исходный файл…”

### 4.2. Частичный успех

Если из 10 файлов 8 применились:

- применить 8
- guided retry генерировать только для 2 сломанных
- опционально: “insert comment with patch + problem” прямо в файл, чтобы пользователь мог вручную довести

### 4.3. Сессионность и кеширование (опционально)

Для качественного guided retry потребуется:

- кешировать “последний apply attempt”
- хранить контекст (оригинал файлов, expected anchors)
- но baseline может начать без этого, постепенно добавляя “history store”

---

## 5) Roadmap развития (эволюционный цикл)

План итераций (как задумано):

1. Реализовать **Validation Submodule + Sanitization Submodule**
2. Опубликовать extension и использовать его в pipeline с:
   - collinc777.context-copy (EditorToLlm временно)
   - RonPark.paste-clipboard-to-files (FilesPatcher временно)

3. Постепенно вытеснять обе зависимости:
   - сначала собственный Files Patcher (через VS Code API)
   - потом собственный EditorToLlm с response prompt, дедупом, устойчивостью

4. Добавить альтернативы full-output:
   - replace-blocks (patch-стратегия “золотая середина”)
   - выбор стратегии per workspace / per LLM

---

## 6) Форматы ответа LLM (Response Strategies)

### 6.1. Full-output (baseline)

LLM возвращает **полные файлы целиком** в виде конкатенации listings.

Плюсы:

- проще парсить
- меньше “тонких” фейлов как у диффов
- предсказуемый apply

Минусы:

- больше токенов и времени

### 6.2. replace-blocks (будущее)

Идея:

- LLM возвращает patch-подобный ответ, но не git diff
- extension делает replace old_text → new_text по якорным строкам “до/после”
- если якорь не найден — guided retry

Это “золотая середина” между git-diff и full-output.

---

## 7) Конфигурация и UX

### 7.1. Принцип

Настроек будет много (регексы, промты, исключения, поведение при ошибках).
Поэтому важно:

- поддержать настройки через VS Code settings
- плюс **собственный конфиг-файл** (например `.llm-copypaster.json`), чтобы:
  - хранить длинные промты
  - переносить конфигурацию между проектами
  - версионировать в репозитории

### 7.1.a. EditorToLlm: режим копирования (context vs path-comment)

Новые ключи (концепт):

```json
{
  "editorToLlm": {
    "copyModeSelection": "quickPick",
    "copyModeFixed": "llmContext"
  }
}
```

- `copyModeSelection`:
  - `quickPick` — показывать выбор режима при копировании
  - `fixed` — режим фиксирован настройкой `copyModeFixed`

- `copyModeFixed`:
  - `llmContext` — baseline формат 2.5.1 (+ опциональный 2.5.2)
  - `pathComment` — формат 2.5.3

### 7.1.b. UX: группировка пунктов контекстного меню в под-меню

По мере роста количества команд в Explorer context menu, рекомендуется группировать их в под-меню:

- флаг: `ux.enableExplorerContextSubmenu`
- если включен — пункты контекстного меню отображаются как подпункты внутри `LLM Copypaster`
- если выключен — пункты отображаются плоским списком (как в baseline)

Концепт:

```json
{
  "ux": {
    "enableExplorerContextSubmenu": true
  }
}
```

### 7.2. Пер-LLM overrides

Нужно позволить:

- общий default prompt / правила
- overrides по `currentLLM = x` (настройка пользователя)

Концепт:

```json
{
  "currentLLM": "chatgpt",
  "prompts": {
    "default": "...",
    "overrides": {
      "claude": "...",
      "gemini": "..."
    }
  }
}
```

### 7.3. Санитизация: правила + исключения

Требование:

- каждый rule может быть отключен:
  - по языкам
  - по путям
  - по patterns (regex on path)

- правила должны быть упорядоченными (важен порядок применения)

### 7.4. Автоформатирование после apply

Опционально:

- включаемое в настройках
- по расширениям файлов
- или только для файлов, которые реально изменились

---

## 8) Команды (Command Palette / Context Menu)

Рекомендуемый набор команд (имена условные):

### 8.1. EditorToLlm

Примечание: команды копирования используют режим выбора/фиксации из раздела 2.5.4 и настроек 7.1.a.

- `LLM Copypaster: Copy Active File as LLM Context`
- `LLM Copypaster: Copy All Open Files as LLM Context`
- `LLM Copypaster: Copy Tab Group Files as LLM Context`
- `LLM Copypaster: Copy Selected Explorer Files as LLM Context`
- `LLM Copypaster: Copy LLM Context (with Response Format Prompt)`
- `LLM Copypaster: Copy LLM Context (without Response Format Prompt)`

### 8.2. LlmToEditor

- `LLM Copypaster: Apply Clipboard to Files`
- `LLM Copypaster: Validate Clipboard Payload`
- `LLM Copypaster: Sanitize Clipboard Payload`
- `LLM Copypaster: Copy Guided Retry Prompt (Last Error)`

---

## 9) Нефункциональные требования

- Надёжность: не падать на edge cases (missing file, duplicate tab, partial parse)
- Прозрачность: пользователь должен понимать, что применилось, что нет, и почему
- Минимизация рутины: guided retry, частичное применение, быстрые команды
- Конфигурируемость: rules, промты, стратегии, исключения, overrides
- API-correctness: применение через VS Code API для совместимости с форматтерами/линтерами/экосистемой

---

## 10) Итог

llm-copypaster задуман как “склейка и эволюция” существующих подходов:

- копирование контекста как у collinc777.context-copy, но с дедупом, устойчивостью и response prompts
- применение в файлы как у RonPark.paste-clipboard-to-files, но через VS Code API и с конфигом
- дальнейшее развитие: replace-blocks, guided retry, сессионность, частичное применение, пер-LLM профили

Этот BL документ фиксирует основу, на которой можно строить implementation и публичный roadmap.
